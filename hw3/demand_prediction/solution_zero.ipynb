{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ocksumoron/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.tsv\")\n",
    "test = pd.read_csv(\"test.tsv\")\n",
    "sample_submission = pd.read_csv(\"sample_submission.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24385 24385\n"
     ]
    }
   ],
   "source": [
    "X = train[train['shift'] == 1].drop(['Num','y','shift'], axis=1)\n",
    "y = train[train['shift'] == 1]['y']\n",
    "print(len(X), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_k(item_id, year):\n",
    "    vals = []\n",
    "    ys = []\n",
    "    data = train[(train['item_id'] == item_id) & (train['year'] == year) & (train['shift'] == 1)].sort_values('week')\n",
    "    if (data.shape[0] == 0):\n",
    "        return 1.0\n",
    "    ys.append(data.iloc[0]['y'])\n",
    "    vals.append(data.iloc[0]['f60'])\n",
    "    \n",
    "    for i in range(1, data.shape[0]):\n",
    "        vals.append(data.iloc[i]['f60'])\n",
    "        ys.append(data.iloc[i]['y'])\n",
    "        \n",
    "    vals = np.array(vals)\n",
    "    ys = np.array(ys)\n",
    "    k = np.median(vals[1:] / ys[:-1])\n",
    "    return k\n",
    "\n",
    "ks_2013 = {}\n",
    "ks_2014 = {}\n",
    "\n",
    "for item_id in test['item_id'].unique():\n",
    "    ks_2013[item_id] = get_k(item_id, 2013)\n",
    "    ks_2014[item_id] = get_k(item_id, 2014)\n",
    "    \n",
    "best_k = (np.median(list(ks_2013.values())) + np.median(list(ks_2014.values()))) * 0.5\n",
    "\n",
    "y *= best_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_13, y_13 = X[X['year'] == 2013], y[X['year'] == 2013]\n",
    "X_14, y_14 = X[(X['year'] == 2014) & (X['week'] <= 50)], y[(X['year'] == 2014) & (X['week'] <= 50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def feature_gen():\n",
    "    features = ['f' + str(i) for i in range(55, 61)]\n",
    "    for i, row in X_14.iterrows():\n",
    "        prev_vals = X_13[(X_13['item_id'] == row['item_id']) & \\\n",
    "                         (X_13['week'] == row['week'] + 2)]\n",
    "        \n",
    "        if prev_vals.shape[0] == 0:\n",
    "            for f in ['f' + str(j) for j in range(55, 61)]:\n",
    "                X_14.set_value(i, 'prev_' + f, 0.0)\n",
    "                \n",
    "            continue\n",
    "            \n",
    "        \n",
    "        prev_val = prev_vals.iloc[0]\n",
    "        \n",
    "        for f in ['f' + str(j) for j in range(55, 61)]:\n",
    "            X_14.set_value(i, 'prev_' + f, prev_val[f])\n",
    "            \n",
    "            \n",
    "    for i, row in test.iterrows():\n",
    "        prev_vals = X_14[(X_14['item_id'] == row['item_id']) & \\\n",
    "                         (X_14['week'] == row['week'] + 2)]\n",
    "        \n",
    "        if prev_vals.shape[0] == 0:\n",
    "            for f in ['f' + str(j) for j in range(55, 61)]:\n",
    "                test.set_value(i, 'prev_' + f, 0.0)\n",
    "                \n",
    "            continue\n",
    "        \n",
    "        prev_val = prev_vals.iloc[0]\n",
    "        \n",
    "        for f in ['f' + str(j) for j in range(55, 61)]:\n",
    "            test.set_value(i, 'prev_' + f, prev_val[f])\n",
    "    \n",
    "    features += ['prev_f' + str(i) for i in range(55, 61)]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ocksumoron/anaconda/lib/python2.7/site-packages/pandas/core/indexing.py:288: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/Users/ocksumoron/anaconda/lib/python2.7/site-packages/pandas/core/indexing.py:465: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "features = feature_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = X_14[X_14['week'] < 40], y_14[X_14['week'] < 40]\n",
    "X_val, y_val = X_14[X_14['week'] >= 40], y_14[X_14['week'] >= 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_smape(y_pred, y_true):\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_true = np.array(y_true)\n",
    "    n = len(y_pred)\n",
    "    return 100. / n * np.sum(np.abs(y_pred - y_true) / (np.abs(y_pred) + np.abs(y_true)))\n",
    "\n",
    "def get_smape_d(y_pred, d_y_true):\n",
    "    y_true = d_y_true.get_label()\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_true = np.array(y_true)\n",
    "    n = len(y_pred)\n",
    "    return 'smape', 100. / n * np.sum(np.abs(y_pred - y_true) / (np.abs(y_pred) + np.abs(y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param = {}\n",
    "param['max_depth'] = 15\n",
    "param['booster'] = 'gbtree'\n",
    "param['objective'] = 'reg:linear'\n",
    "param['eta'] = 0.05\n",
    "param['colsample_bytree'] = 1\n",
    "param['subsample'] = 0.8\n",
    "\n",
    "numround = 2001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-smape:89.8795\teval-smape:88.767\n",
      "[100]\ttrain-smape:3.8602\teval-smape:14.3006\n",
      "[200]\ttrain-smape:4.01799\teval-smape:14.5061\n",
      "[300]\ttrain-smape:3.51311\teval-smape:14.4481\n",
      "[400]\ttrain-smape:2.96415\teval-smape:14.5934\n",
      "[500]\ttrain-smape:2.56326\teval-smape:14.5526\n",
      "[600]\ttrain-smape:2.0909\teval-smape:14.6037\n",
      "[700]\ttrain-smape:1.73367\teval-smape:14.6019\n",
      "[800]\ttrain-smape:1.35807\teval-smape:14.6326\n",
      "[900]\ttrain-smape:1.00322\teval-smape:14.6459\n",
      "[1000]\ttrain-smape:0.798811\teval-smape:14.6189\n",
      "[1100]\ttrain-smape:0.648265\teval-smape:14.6528\n",
      "[1200]\ttrain-smape:0.518767\teval-smape:14.6299\n",
      "[1300]\ttrain-smape:0.431089\teval-smape:14.6764\n",
      "[1400]\ttrain-smape:0.416075\teval-smape:14.7061\n",
      "[1500]\ttrain-smape:0.365439\teval-smape:14.6592\n",
      "[1600]\ttrain-smape:0.33548\teval-smape:14.6558\n",
      "[1700]\ttrain-smape:0.327377\teval-smape:14.6469\n",
      "[1800]\ttrain-smape:0.323039\teval-smape:14.6212\n",
      "[1900]\ttrain-smape:0.30874\teval-smape:14.6947\n",
      "[2000]\ttrain-smape:0.315407\teval-smape:14.6953\n",
      "CPU times: user 54.8 s, sys: 373 ms, total: 55.2 s\n",
      "Wall time: 55.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Xdata = xgb.DMatrix(data = X[features], label = y)\n",
    "Xdatatrain = xgb.DMatrix(data = X_train[features], label = y_train)\n",
    "Xdatatest = xgb.DMatrix(data = X_val[features], label = y_val)\n",
    "\n",
    "plst = list(param.items())\n",
    "watchlist = [(Xdatatrain, 'train'), (Xdatatest, 'eval')]            \n",
    "\n",
    "output = {}\n",
    "\n",
    "bst = xgb.train(plst, Xdatatrain, numround, feval=get_smape_d, evals=watchlist, evals_result=output, verbose_eval=100)\n",
    "# ypredxgb_tr = bst.predict(Xdatatrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def grid_search():\n",
    "    max_depths = [3, 4, 5, 6, 7, 8, 10, 12, 15]\n",
    "    learning_rates = [0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.13, 0.15, 0.17, 0.2]\n",
    "    subsamples = [0.8, 0.9, 1]\n",
    "    colsample_bytrees = [0.8, 0.9, 1]\n",
    "    \n",
    "    \n",
    "    numround = 2001\n",
    "    \n",
    "    best_q = 15.0\n",
    "    \n",
    "    for max_depth in max_depths:\n",
    "        \n",
    "        print(\"MAX_DEPTH =\", max_depth)\n",
    "        \n",
    "        with open(\"output\" + str(max_depth), 'w') as f:\n",
    "        \n",
    "            for learning_rate in learning_rates:\n",
    "\n",
    "                print(\"LEARNING_RATE =\", learning_rate)\n",
    "\n",
    "                for subsample in subsamples:\n",
    "\n",
    "                    print (\"SUBSAMPLE =\", subsample)\n",
    "\n",
    "                    for colsample_bytree in colsample_bytrees:\n",
    "\n",
    "                        print (\"COLSAMPLE_BYTREE =\", colsample_bytree)\n",
    "                        \n",
    "                        param = {}\n",
    "                        param['max_depth'] = max_depth\n",
    "                        param['booster'] = 'gbtree'\n",
    "                        param['objective'] = 'reg:linear'\n",
    "                        param['eta'] = learning_rate\n",
    "                        param['colsample_bytree'] = colsample_bytree\n",
    "                        param['subsample'] = subsample\n",
    "                        \n",
    "                        plst = list(param.items())\n",
    "                            \n",
    "                        output = {}\n",
    "\n",
    "                        bst = xgb.train(plst, Xdatatrain, \\\n",
    "                                        numround, feval=get_smape_d, \\\n",
    "                                        evals=watchlist, evals_result=output, \\\n",
    "                                        verbose_eval=False)\n",
    "                        \n",
    "                        f.write(\"LEARNING_RATE =\" + str(learning_rate) + \\\n",
    "                                \", SUBSAMPLE =\" + str(subsample) + \\\n",
    "                                \", COLSAMPLE_BYTREE =\" + str(colsample_bytree) + \"\\n\")\n",
    "            \n",
    "                        output_smape = output['eval']['smape']\n",
    "                        \n",
    "                        for i in range(0, len(output_smape), 100):\n",
    "                            f.write(str(i) + \": \" + str(output_smape[i]) + \"\\n\")\n",
    "                            if (output_smape[i] < best_q):\n",
    "                                best_q = output_smape[i]\n",
    "                                print(\"BEST = \" + str(best_q))\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX_DEPTH = 3\n",
      "LEARNING_RATE = 0.05\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.06\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.07\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.08\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.09\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.1\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.13\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.15\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.17\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.2\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "MAX_DEPTH = 4\n",
      "LEARNING_RATE = 0.05\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.06\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.07\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.08\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.09\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.1\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.13\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.15\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.17\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.2\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "MAX_DEPTH = 5\n",
      "LEARNING_RATE = 0.05\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.06\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.07\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.08\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.09\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.1\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.13\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.15\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.17\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.2\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "MAX_DEPTH = 6\n",
      "LEARNING_RATE = 0.05\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.06\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.07\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.08\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.09\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.1\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.13\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.15\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.17\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.2\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "MAX_DEPTH = 7\n",
      "LEARNING_RATE = 0.05\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "BEST = 14.994107\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "BEST = 14.992693\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "BEST = 14.960349\n",
      "BEST = 14.900433\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.06\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.07\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.08\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.09\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.1\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.13\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.15\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.17\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.2\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "MAX_DEPTH = 8\n",
      "LEARNING_RATE = 0.05\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "BEST = 14.896152\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.06\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "BEST = 14.881314\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "BEST = 14.844651\n",
      "BEST = 14.814131\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.07\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.08\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.09\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.1\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.13\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.15\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.17\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.2\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "MAX_DEPTH = 10\n",
      "LEARNING_RATE = 0.05\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.06\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.07\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.08\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.09\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.1\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.13\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.15\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.17\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.2\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "MAX_DEPTH = 12\n",
      "LEARNING_RATE = 0.05\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "BEST = 14.729932\n",
      "BEST = 14.659017\n",
      "BEST = 14.6359\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.06\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.07\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.08\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.09\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.1\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.13\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.15\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.17\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.2\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "MAX_DEPTH = 15\n",
      "LEARNING_RATE = 0.05\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "BEST = 14.300592\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.06\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.07\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.08\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.09\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.1\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.13\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.15\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.17\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "LEARNING_RATE = 0.2\n",
      "SUBSAMPLE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 0.9\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "SUBSAMPLE = 1\n",
      "COLSAMPLE_BYTREE = 0.8\n",
      "COLSAMPLE_BYTREE = 0.9\n",
      "COLSAMPLE_BYTREE = 1\n",
      "CPU times: user 6h 4min 36s, sys: 3min 11s, total: 6h 7min 47s\n",
      "Wall time: 6h 10min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grid_search():\n",
    "    max_depths = [3, 4, 5, 6, 7, 8, 10, 12, 15]\n",
    "    learning_rates = [0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.13, 0.15, 0.17, 0.2]\n",
    "    subsamples = [0.8, 0.9, 1]\n",
    "    colsample_bytrees = [0.8, 0.9, 1]\n",
    "    \n",
    "    \n",
    "    numround = 2001\n",
    "    \n",
    "    best_q = 15.0\n",
    "    \n",
    "    for max_depth in max_depths:\n",
    "        \n",
    "        print(\"MAX_DEPTH =\", max_depth)\n",
    "        \n",
    "        with open(\"output\" + str(max_depth), 'w') as f:\n",
    "        \n",
    "            for learning_rate in learning_rates:\n",
    "\n",
    "                print(\"LEARNING_RATE =\", learning_rate)\n",
    "\n",
    "                for subsample in subsamples:\n",
    "\n",
    "                    print (\"SUBSAMPLE =\", subsample)\n",
    "\n",
    "                    for colsample_bytree in colsample_bytrees:\n",
    "\n",
    "                        print (\"COLSAMPLE_BYTREE =\", colsample_bytree)\n",
    "                        \n",
    "                        param = {}\n",
    "                        param['max_depth'] = max_depth\n",
    "                        param['booster'] = 'gbtree'\n",
    "                        param['objective'] = 'reg:linear'\n",
    "                        param['eta'] = learning_rate\n",
    "                        param['colsample_bytree'] = colsample_bytree\n",
    "                        param['subsample'] = subsample\n",
    "                        \n",
    "                        plst = list(param.items())\n",
    "                            \n",
    "                        output = {}\n",
    "\n",
    "                        bst = xgb.train(plst, Xdatatrain, \\\n",
    "                                        numround, feval=get_smape_d, \\\n",
    "                                        evals=watchlist, evals_result=output, \\\n",
    "                                        verbose_eval=False)\n",
    "                        \n",
    "                        f.write(\"LEARNING_RATE =\" + str(learning_rate) + \\\n",
    "                                \", SUBSAMPLE =\" + str(subsample) + \\\n",
    "                                \", COLSAMPLE_BYTREE =\" + str(colsample_bytree) + \"\\n\")\n",
    "            \n",
    "                        output_smape = output['eval']['smape']\n",
    "                        \n",
    "                        for i in range(0, len(output_smape), 100):\n",
    "                            f.write(str(i) + \": \" + str(output_smape[i]) + \"\\n\")\n",
    "                            if (output_smape[i] < best_q):\n",
    "                                best_q = output_smape[i]\n",
    "                                print(\"BEST = \" + str(best_q))\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.7642763564\n",
      "CPU times: user 1min 4s, sys: 678 ms, total: 1min 5s\n",
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "rf_model = RandomForestRegressor(n_estimators=700, oob_score = True)\n",
    "rf_model.fit(X_train[features], y_train)\n",
    "\n",
    "print (get_smape(rf_model.predict(X_val[features]), y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11a7b86d0>]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgUAAAFkCAYAAACw3EhvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a7c1550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "size = 5\n",
    "train_vals =  (X_14['week'] <= size)\n",
    "X_train, y_train = X_14[train_vals], y_14[train_vals]\n",
    "\n",
    "res = []\n",
    "\n",
    "rf_model.fit(X_train[features], y_train)\n",
    "\n",
    "for i in range(size + 1, 51):\n",
    "        \n",
    "    test_vals = (X_14['week'] == i)\n",
    "    X_val, y_val = X_14[test_vals], y_14[test_vals]\n",
    "\n",
    "        \n",
    "    y_pred = rf_model.predict(X_val[features])\n",
    "    \n",
    "    res.append(get_smape(y_pred, y_val))\n",
    "\n",
    "plt.plot(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_cross_validation(model, features, f=lambda x: x, inv=lambda x: x):\n",
    "    cv = []\n",
    "    for fold in [20, 30, 40]:\n",
    "        \n",
    "        train_vals = X_14['week'] <= fold\n",
    "        X_train, y_train = X_14[train_vals], y_14[train_vals]\n",
    "        \n",
    "        test_vals = (X_14['week'] > fold) & (X_14['week'] <= fold + 10)\n",
    "        X_val, y_val = X_14[test_vals], y_14[test_vals]\n",
    "        \n",
    "        model.fit(X_train[features], f(y_train))\n",
    "        \n",
    "        y_pred = model.predict(X_val[features])\n",
    "        \n",
    "        cv.append(get_smape(inv(y_pred), y_val))\n",
    "        \n",
    "    return cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.4106218557152506, 11.571065672062668, 14.897333727267171]\n",
      "CPU times: user 2min 20s, sys: 1.2 s, total: 2min 21s\n",
      "Wall time: 2min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv = my_cross_validation(rf_model, features)\n",
    "print(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.2360837860543814, 11.081189051954642, 14.063932545790538]\n",
      "CPU times: user 2min 17s, sys: 2.33 s, total: 2min 20s\n",
      "Wall time: 2min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv = my_cross_validation(rf_model, features, np.log, np.exp)\n",
    "print(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.2268165148619055, 11.062919227203171, 14.062203114591687]\n",
      "CPU times: user 3min 11s, sys: 3.62 s, total: 3min 14s\n",
      "Wall time: 3min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf_model = RandomForestRegressor(n_estimators=1000)\n",
    "cv = my_cross_validation(rf_model, features, np.log, np.exp)\n",
    "print(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.2135936606397291, 11.067382395644351, 14.042284714545389]\n",
      "CPU times: user 3min 1s, sys: 2.55 s, total: 3min 3s\n",
      "Wall time: 3min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf_model = RandomForestRegressor(n_estimators=1000)\n",
    "cv = my_cross_validation(rf_model, features, lambda x: np.log(x + 1), lambda x: np.exp(x) - 1)\n",
    "print(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 24s, sys: 1.11 s, total: 1min 25s\n",
      "Wall time: 1min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "rf_model = RandomForestRegressor(n_estimators=700, oob_score = True)\n",
    "rf_model.fit(X_14[features], y_14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_shift(model, features, is_df=False):\n",
    "    test_mod = test[test['shift'] == 1].drop(['Num', 'shift'], axis=1)\n",
    "    if (is_df):\n",
    "        to_test = xgb.DMatrix(data = test_mod[features])\n",
    "        predicted = model.predict(to_test)\n",
    "    else:\n",
    "        predicted = model.predict(test_mod[features])\n",
    "    all_predicted_dict = {}\n",
    "    all_predicted = []\n",
    "    i = 0\n",
    "    for _, row in test_mod.iterrows():\n",
    "        all_predicted_dict[(row.item_id, row.week)] = predicted[i]\n",
    "        i += 1\n",
    "    for _, row in test.iterrows():\n",
    "        all_predicted.append(all_predicted_dict[(row.item_id, row.week)])\n",
    "    return all_predicted / best_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# to_fit = X_14['week'] >= 40\n",
    "# rf_model.fit(X_14[to_fit][features], y_14[to_fit])\n",
    "sample_submission['y'] = add_shift(bst, features, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def add_bad(submission):\n",
    "    bad_ids = {}\n",
    "    bad_nums = {}\n",
    "    for item_id in test['item_id'].unique():\n",
    "        if (test[test['item_id'] == item_id].shape[0] != 3):\n",
    "            bad_ids[item_id] = np.mean(test[test['item_id'] == item_id]['f60']) + 10.0\n",
    "\n",
    "    for _, row in test.iterrows():\n",
    "        if row.item_id in bad_ids:\n",
    "            bad_nums[row.Num] = bad_ids[row.item_id]\n",
    "    \n",
    "    for i, row in submission.iterrows():\n",
    "        if row.Num in bad_nums:\n",
    "            submission.set_value(i, 'y', bad_nums[row.Num])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_good(submission):\n",
    "    ans = {}\n",
    "    for item_id in test['item_id'].unique():\n",
    "        if test[(test['item_id'] == item_id) & (test['week'] == 5) & (test['shift'] == 1)].shape[0] == 1:\n",
    "            ans[(item_id, 4)] = \\\n",
    "                np.array(test[(test['item_id'] == item_id) & \\\n",
    "                              (test['week'] == 5) & \\\n",
    "                              (test['shift'] == 1)]['f60'])[0] / best_k\n",
    "            ans[(item_id, 3)] = \\\n",
    "                np.array(test[(test['item_id'] == item_id) & \\\n",
    "                              (test['week'] == 5) & \\\n",
    "                              (test['shift'] == 1)]['f59'])[0] / best_k\n",
    "        elif test[(test['item_id'] == item_id) & (test['week'] == 4) & (test['shift'] == 1)].shape[0] == 1:\n",
    "            ans[(item_id, 3)] = \\\n",
    "                np.array(test[(test['item_id'] == item_id) & \\\n",
    "                              (test['week'] == 4) & \\\n",
    "                              (test['shift'] == 1)]['f60'])[0] / best_k\n",
    "            \n",
    "    for i, row in test.iterrows():\n",
    "        if (row.item_id, row.week) in ans:\n",
    "            submission.set_value(i, 'y', int(ans[(row.item_id, row.week)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "add_good(sample_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>348622</td>\n",
       "      <td>1840.531372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>348623</td>\n",
       "      <td>30782.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>348624</td>\n",
       "      <td>310838.406250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>348625</td>\n",
       "      <td>35613.734375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>348626</td>\n",
       "      <td>163.086380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>348627</td>\n",
       "      <td>121895.007812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>348628</td>\n",
       "      <td>85186.328125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>348629</td>\n",
       "      <td>84447.046875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>348630</td>\n",
       "      <td>91909.578125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>348631</td>\n",
       "      <td>1873.335205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>348632</td>\n",
       "      <td>1723.658325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>348633</td>\n",
       "      <td>67087.578125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>348634</td>\n",
       "      <td>309945.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>348635</td>\n",
       "      <td>27248.384766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>348636</td>\n",
       "      <td>2351.465332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>348637</td>\n",
       "      <td>169403.671875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>348638</td>\n",
       "      <td>102702.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>348639</td>\n",
       "      <td>455223.406250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>348640</td>\n",
       "      <td>498403.281250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>348641</td>\n",
       "      <td>1613.356323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>348642</td>\n",
       "      <td>108603.031250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>348643</td>\n",
       "      <td>91886.359375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>348644</td>\n",
       "      <td>1302.324707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>348645</td>\n",
       "      <td>27161.980469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>348646</td>\n",
       "      <td>6407.671387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>348647</td>\n",
       "      <td>126038.539062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>348648</td>\n",
       "      <td>6262.474121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>348649</td>\n",
       "      <td>25066.259766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>348650</td>\n",
       "      <td>4628.424805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>348651</td>\n",
       "      <td>22166.818359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>351499</td>\n",
       "      <td>92.382912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>351500</td>\n",
       "      <td>221210.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>351501</td>\n",
       "      <td>17765.824219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>351502</td>\n",
       "      <td>16286.300781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>351503</td>\n",
       "      <td>491.511353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>351504</td>\n",
       "      <td>439.122742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>351505</td>\n",
       "      <td>14255.278320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>351506</td>\n",
       "      <td>480.144806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>351507</td>\n",
       "      <td>65.079521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>351508</td>\n",
       "      <td>99196.898438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>351509</td>\n",
       "      <td>657791.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>351510</td>\n",
       "      <td>225091.453125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>351511</td>\n",
       "      <td>534749.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>351512</td>\n",
       "      <td>22495.365234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>351513</td>\n",
       "      <td>1499.285156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>351514</td>\n",
       "      <td>26654.576172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>351515</td>\n",
       "      <td>457323.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>351516</td>\n",
       "      <td>121878.593750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>351517</td>\n",
       "      <td>160633.390625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>351518</td>\n",
       "      <td>492146.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>351519</td>\n",
       "      <td>4414.092773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>351520</td>\n",
       "      <td>55.183971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>351521</td>\n",
       "      <td>291.082306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>351522</td>\n",
       "      <td>330.947205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>351523</td>\n",
       "      <td>4721.272949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>351524</td>\n",
       "      <td>35591.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>351525</td>\n",
       "      <td>20700.380859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>351526</td>\n",
       "      <td>17104.691406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>351527</td>\n",
       "      <td>430.097382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>351528</td>\n",
       "      <td>4838.480469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2016 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Num              y\n",
       "0     348622    1840.531372\n",
       "1     348623   30782.312500\n",
       "2     348624  310838.406250\n",
       "3     348625   35613.734375\n",
       "4     348626     163.086380\n",
       "5     348627  121895.007812\n",
       "6     348628   85186.328125\n",
       "7     348629   84447.046875\n",
       "8     348630   91909.578125\n",
       "9     348631    1873.335205\n",
       "10    348632    1723.658325\n",
       "11    348633   67087.578125\n",
       "12    348634  309945.375000\n",
       "13    348635   27248.384766\n",
       "14    348636    2351.465332\n",
       "15    348637  169403.671875\n",
       "16    348638  102702.500000\n",
       "17    348639  455223.406250\n",
       "18    348640  498403.281250\n",
       "19    348641    1613.356323\n",
       "20    348642  108603.031250\n",
       "21    348643   91886.359375\n",
       "22    348644    1302.324707\n",
       "23    348645   27161.980469\n",
       "24    348646    6407.671387\n",
       "25    348647  126038.539062\n",
       "26    348648    6262.474121\n",
       "27    348649   25066.259766\n",
       "28    348650    4628.424805\n",
       "29    348651   22166.818359\n",
       "...      ...            ...\n",
       "1986  351499      92.382912\n",
       "1987  351500  221210.687500\n",
       "1988  351501   17765.824219\n",
       "1989  351502   16286.300781\n",
       "1990  351503     491.511353\n",
       "1991  351504     439.122742\n",
       "1992  351505   14255.278320\n",
       "1993  351506     480.144806\n",
       "1994  351507      65.079521\n",
       "1995  351508   99196.898438\n",
       "1996  351509  657791.750000\n",
       "1997  351510  225091.453125\n",
       "1998  351511  534749.312500\n",
       "1999  351512   22495.365234\n",
       "2000  351513    1499.285156\n",
       "2001  351514   26654.576172\n",
       "2002  351515  457323.125000\n",
       "2003  351516  121878.593750\n",
       "2004  351517  160633.390625\n",
       "2005  351518  492146.250000\n",
       "2006  351519    4414.092773\n",
       "2007  351520      55.183971\n",
       "2008  351521     291.082306\n",
       "2009  351522     330.947205\n",
       "2010  351523    4721.272949\n",
       "2011  351524   35591.187500\n",
       "2012  351525   20700.380859\n",
       "2013  351526   17104.691406\n",
       "2014  351527     430.097382\n",
       "2015  351528    4838.480469\n",
       "\n",
       "[2016 rows x 2 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_submission.to_csv('xgb_overfit_submission_1.tsv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>item_id</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>...</th>\n",
       "      <th>f51</th>\n",
       "      <th>f52</th>\n",
       "      <th>f53</th>\n",
       "      <th>f54</th>\n",
       "      <th>f55</th>\n",
       "      <th>f56</th>\n",
       "      <th>f57</th>\n",
       "      <th>f58</th>\n",
       "      <th>f59</th>\n",
       "      <th>f60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>20442092</td>\n",
       "      <td>270.0</td>\n",
       "      <td>980.0</td>\n",
       "      <td>6140.0</td>\n",
       "      <td>8292.0</td>\n",
       "      <td>780.0</td>\n",
       "      <td>426.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>...</td>\n",
       "      <td>370.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>830.0</td>\n",
       "      <td>730.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>20442091</td>\n",
       "      <td>670.0</td>\n",
       "      <td>2830.0</td>\n",
       "      <td>11530.0</td>\n",
       "      <td>10397.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>960.0</td>\n",
       "      <td>760.0</td>\n",
       "      <td>...</td>\n",
       "      <td>460.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>505.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>930.0</td>\n",
       "      <td>730.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>20442076</td>\n",
       "      <td>38056.0</td>\n",
       "      <td>40185.0</td>\n",
       "      <td>45733.0</td>\n",
       "      <td>59710.0</td>\n",
       "      <td>39982.0</td>\n",
       "      <td>45846.0</td>\n",
       "      <td>43680.0</td>\n",
       "      <td>...</td>\n",
       "      <td>41765.0</td>\n",
       "      <td>52590.0</td>\n",
       "      <td>31452.0</td>\n",
       "      <td>44420.0</td>\n",
       "      <td>41865.0</td>\n",
       "      <td>52705.0</td>\n",
       "      <td>36102.0</td>\n",
       "      <td>44163.0</td>\n",
       "      <td>45239.0</td>\n",
       "      <td>76670.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>20441997</td>\n",
       "      <td>18817.0</td>\n",
       "      <td>20110.0</td>\n",
       "      <td>26368.0</td>\n",
       "      <td>31412.0</td>\n",
       "      <td>23182.0</td>\n",
       "      <td>24565.0</td>\n",
       "      <td>27075.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25230.0</td>\n",
       "      <td>27850.0</td>\n",
       "      <td>21390.0</td>\n",
       "      <td>27090.0</td>\n",
       "      <td>23170.0</td>\n",
       "      <td>29705.0</td>\n",
       "      <td>19140.0</td>\n",
       "      <td>22055.0</td>\n",
       "      <td>23200.0</td>\n",
       "      <td>36280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>20441990</td>\n",
       "      <td>47480.0</td>\n",
       "      <td>47619.0</td>\n",
       "      <td>89708.0</td>\n",
       "      <td>166338.0</td>\n",
       "      <td>37620.0</td>\n",
       "      <td>85607.0</td>\n",
       "      <td>92461.0</td>\n",
       "      <td>...</td>\n",
       "      <td>44290.0</td>\n",
       "      <td>46412.0</td>\n",
       "      <td>29320.0</td>\n",
       "      <td>21140.0</td>\n",
       "      <td>28406.0</td>\n",
       "      <td>65056.0</td>\n",
       "      <td>31886.0</td>\n",
       "      <td>48750.0</td>\n",
       "      <td>36520.0</td>\n",
       "      <td>101820.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     year  week   item_id       f1       f2       f3        f4       f5  \\\n",
       "696  2013     1  20442092    270.0    980.0   6140.0    8292.0    780.0   \n",
       "697  2013     1  20442091    670.0   2830.0  11530.0   10397.0    260.0   \n",
       "698  2013     1  20442076  38056.0  40185.0  45733.0   59710.0  39982.0   \n",
       "699  2013     1  20441997  18817.0  20110.0  26368.0   31412.0  23182.0   \n",
       "700  2013     1  20441990  47480.0  47619.0  89708.0  166338.0  37620.0   \n",
       "\n",
       "          f6       f7    ...         f51      f52      f53      f54      f55  \\\n",
       "696    426.0    120.0    ...       370.0    151.0    220.0    220.0    450.0   \n",
       "697    960.0    760.0    ...       460.0    400.0    350.0    500.0    480.0   \n",
       "698  45846.0  43680.0    ...     41765.0  52590.0  31452.0  44420.0  41865.0   \n",
       "699  24565.0  27075.0    ...     25230.0  27850.0  21390.0  27090.0  23170.0   \n",
       "700  85607.0  92461.0    ...     44290.0  46412.0  29320.0  21140.0  28406.0   \n",
       "\n",
       "         f56      f57      f58      f59       f60  \n",
       "696    290.0    240.0    210.0    830.0     730.0  \n",
       "697    505.0    310.0    230.0    930.0     730.0  \n",
       "698  52705.0  36102.0  44163.0  45239.0   76670.0  \n",
       "699  29705.0  19140.0  22055.0  23200.0   36280.0  \n",
       "700  65056.0  31886.0  48750.0  36520.0  101820.0  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_13.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "869.38824759426757"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_14.iloc[0]['prev_f59']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "941"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_14.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year        2.014000e+03\n",
       "week        1.000000e+00\n",
       "item_id     2.044232e+07\n",
       "f1          8.291388e+02\n",
       "f2          9.418373e+02\n",
       "f3          1.231633e+03\n",
       "f4          9.498872e+02\n",
       "f5          7.405900e+02\n",
       "f6          7.405900e+02\n",
       "f7          8.130390e+02\n",
       "f8          9.981865e+02\n",
       "f9          1.078685e+03\n",
       "f10         9.015878e+02\n",
       "f11         9.981865e+02\n",
       "f12         1.135035e+03\n",
       "f13         1.215534e+03\n",
       "f14         5.554425e+02\n",
       "f15         1.038436e+03\n",
       "f16         1.135035e+03\n",
       "f17         9.096377e+02\n",
       "f18         1.263833e+03\n",
       "f19         4.668937e+02\n",
       "f20         9.981865e+02\n",
       "f21         7.969392e+02\n",
       "f22         1.529479e+03\n",
       "f23         3.300455e+02\n",
       "f24         1.416781e+03\n",
       "f25         1.424831e+03\n",
       "f26         1.585829e+03\n",
       "f27         6.761909e+02\n",
       "                ...     \n",
       "f37         8.130390e+02\n",
       "f38         9.981865e+02\n",
       "f39         1.078685e+03\n",
       "f40         9.015878e+02\n",
       "f41         9.981865e+02\n",
       "f42         1.135035e+03\n",
       "f43         1.215534e+03\n",
       "f44         5.554425e+02\n",
       "f45         1.038436e+03\n",
       "f46         1.135035e+03\n",
       "f47         9.096377e+02\n",
       "f48         1.263833e+03\n",
       "f49         4.668937e+02\n",
       "f50         9.981865e+02\n",
       "f51         7.969392e+02\n",
       "f52         1.529479e+03\n",
       "f53         3.300455e+02\n",
       "f54         1.416781e+03\n",
       "f55         1.424831e+03\n",
       "f56         1.585829e+03\n",
       "f57         6.761909e+02\n",
       "f58         7.888893e+02\n",
       "f59         9.418373e+02\n",
       "f60         1.722677e+03\n",
       "prev_f55    6.037418e+02\n",
       "prev_f56    9.418373e+02\n",
       "prev_f57    8.130390e+02\n",
       "prev_f58    1.964173e+03\n",
       "prev_f59    8.693882e+02\n",
       "prev_f60    4.346941e+02\n",
       "Name: 36242, dtype: float64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_14.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([    6.,   185.,   231.,   597.,  1290.,  1615.,  2747.,  2591.,\n",
       "         1592.,   318.]),\n",
       " array([  0.69314718,   2.17711137,   3.66107556,   5.14503975,\n",
       "          6.62900394,   8.11296813,   9.59693233,  11.08089652,\n",
       "         12.56486071,  14.0488249 ,  15.53278909]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQ0CSGmYISFLDDAFJatj/AfAniNQF/no+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x145f75278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.log(1 + y_14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36242     6.846943\n",
       "36243     6.453625\n",
       "36244     7.012115\n",
       "36245     9.617071\n",
       "36246     8.203578\n",
       "36247    10.480269\n",
       "36248     9.473320\n",
       "36249     3.465736\n",
       "36250    10.589560\n",
       "36251     2.772589\n",
       "36252    10.458521\n",
       "36253    12.151854\n",
       "36254    14.079077\n",
       "36255    13.267497\n",
       "36256    14.618260\n",
       "36257    12.922018\n",
       "36258    10.170227\n",
       "36259    14.506457\n",
       "36260    10.934196\n",
       "36261    13.046626\n",
       "36262    11.350301\n",
       "36263     8.860925\n",
       "36264     8.511980\n",
       "36265    11.460526\n",
       "36266    11.470133\n",
       "36267    10.623058\n",
       "36268    11.393894\n",
       "36269     9.069928\n",
       "36270    12.740130\n",
       "36271    10.656365\n",
       "           ...    \n",
       "69285     3.465736\n",
       "69286    12.526441\n",
       "69287     9.868793\n",
       "69288     5.451038\n",
       "69289     2.772589\n",
       "69290    10.053845\n",
       "69291     5.996452\n",
       "69292     4.158883\n",
       "69293     6.669498\n",
       "69294     6.073045\n",
       "69295    11.727650\n",
       "69296    13.515954\n",
       "69297    12.663596\n",
       "69298    13.332060\n",
       "69299    10.198766\n",
       "69300     7.075809\n",
       "69301    10.485228\n",
       "69302    11.822049\n",
       "69303    13.258552\n",
       "69304     4.718499\n",
       "69305     6.244167\n",
       "69306     6.011267\n",
       "69307     8.645410\n",
       "69308    10.731493\n",
       "69309     9.862613\n",
       "69310     9.798738\n",
       "69311     6.467699\n",
       "69312     8.462737\n",
       "69313    12.327976\n",
       "69314    13.289245\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(y_14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num</th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>shift</th>\n",
       "      <th>item_id</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>...</th>\n",
       "      <th>f57</th>\n",
       "      <th>f58</th>\n",
       "      <th>f59</th>\n",
       "      <th>f60</th>\n",
       "      <th>prev_f55</th>\n",
       "      <th>prev_f56</th>\n",
       "      <th>prev_f57</th>\n",
       "      <th>prev_f58</th>\n",
       "      <th>prev_f59</th>\n",
       "      <th>prev_f60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>348622</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>20447918</td>\n",
       "      <td>1545.579107</td>\n",
       "      <td>1320.182154</td>\n",
       "      <td>1816.055451</td>\n",
       "      <td>2899.570804</td>\n",
       "      <td>1682.427257</td>\n",
       "      <td>...</td>\n",
       "      <td>1902.994275</td>\n",
       "      <td>1642.177801</td>\n",
       "      <td>2081.701860</td>\n",
       "      <td>2076.871925</td>\n",
       "      <td>2092.971707</td>\n",
       "      <td>2833.561696</td>\n",
       "      <td>1690.477148</td>\n",
       "      <td>1143.084548</td>\n",
       "      <td>1143.084548</td>\n",
       "      <td>2109.071490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>348623</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>20447902</td>\n",
       "      <td>14628.262255</td>\n",
       "      <td>20261.576104</td>\n",
       "      <td>18667.697650</td>\n",
       "      <td>15592.639218</td>\n",
       "      <td>20796.088878</td>\n",
       "      <td>...</td>\n",
       "      <td>27240.831758</td>\n",
       "      <td>29494.801289</td>\n",
       "      <td>38826.235146</td>\n",
       "      <td>34303.806281</td>\n",
       "      <td>20052.278933</td>\n",
       "      <td>23248.085732</td>\n",
       "      <td>13906.992005</td>\n",
       "      <td>7132.203587</td>\n",
       "      <td>14924.498250</td>\n",
       "      <td>14811.799774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>348624</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>20447732</td>\n",
       "      <td>185287.565279</td>\n",
       "      <td>237128.864488</td>\n",
       "      <td>283460.818172</td>\n",
       "      <td>230395.935504</td>\n",
       "      <td>325326.692228</td>\n",
       "      <td>...</td>\n",
       "      <td>332777.671506</td>\n",
       "      <td>395494.373700</td>\n",
       "      <td>460741.961682</td>\n",
       "      <td>460299.217667</td>\n",
       "      <td>174668.148833</td>\n",
       "      <td>202915.216989</td>\n",
       "      <td>172518.827887</td>\n",
       "      <td>60327.494492</td>\n",
       "      <td>103668.108613</td>\n",
       "      <td>113390.767182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>348625</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>20443951</td>\n",
       "      <td>33648.545138</td>\n",
       "      <td>39315.668530</td>\n",
       "      <td>43578.890900</td>\n",
       "      <td>32940.154714</td>\n",
       "      <td>41183.243284</td>\n",
       "      <td>...</td>\n",
       "      <td>24726.045753</td>\n",
       "      <td>30476.888013</td>\n",
       "      <td>47724.584858</td>\n",
       "      <td>54690.960687</td>\n",
       "      <td>42442.246265</td>\n",
       "      <td>46930.865588</td>\n",
       "      <td>31491.174302</td>\n",
       "      <td>17436.064299</td>\n",
       "      <td>31029.110548</td>\n",
       "      <td>27965.321964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>348626</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>20443944</td>\n",
       "      <td>7132.203587</td>\n",
       "      <td>9440.912378</td>\n",
       "      <td>5329.027962</td>\n",
       "      <td>2983.289672</td>\n",
       "      <td>4565.898278</td>\n",
       "      <td>...</td>\n",
       "      <td>32.199565</td>\n",
       "      <td>48.299347</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7244.902063</td>\n",
       "      <td>11192.568699</td>\n",
       "      <td>8690.662519</td>\n",
       "      <td>6488.212292</td>\n",
       "      <td>5892.520345</td>\n",
       "      <td>6473.722488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Num  year  week  shift   item_id             f1             f2  \\\n",
       "0  348622  2015     3      3  20447918    1545.579107    1320.182154   \n",
       "1  348623  2015     3      3  20447902   14628.262255   20261.576104   \n",
       "2  348624  2015     3      3  20447732  185287.565279  237128.864488   \n",
       "3  348625  2015     3      3  20443951   33648.545138   39315.668530   \n",
       "4  348626  2015     3      3  20443944    7132.203587    9440.912378   \n",
       "\n",
       "              f3             f4             f5      ...                  f57  \\\n",
       "0    1816.055451    2899.570804    1682.427257      ...          1902.994275   \n",
       "1   18667.697650   15592.639218   20796.088878      ...         27240.831758   \n",
       "2  283460.818172  230395.935504  325326.692228      ...        332777.671506   \n",
       "3   43578.890900   32940.154714   41183.243284      ...         24726.045753   \n",
       "4    5329.027962    2983.289672    4565.898278      ...            32.199565   \n",
       "\n",
       "             f58            f59            f60       prev_f55       prev_f56  \\\n",
       "0    1642.177801    2081.701860    2076.871925    2092.971707    2833.561696   \n",
       "1   29494.801289   38826.235146   34303.806281   20052.278933   23248.085732   \n",
       "2  395494.373700  460741.961682  460299.217667  174668.148833  202915.216989   \n",
       "3   30476.888013   47724.584858   54690.960687   42442.246265   46930.865588   \n",
       "4      48.299347       0.000000       0.000000    7244.902063   11192.568699   \n",
       "\n",
       "        prev_f57      prev_f58       prev_f59       prev_f60  \n",
       "0    1690.477148   1143.084548    1143.084548    2109.071490  \n",
       "1   13906.992005   7132.203587   14924.498250   14811.799774  \n",
       "2  172518.827887  60327.494492  103668.108613  113390.767182  \n",
       "3   31491.174302  17436.064299   31029.110548   27965.321964  \n",
       "4    8690.662519   6488.212292    5892.520345    6473.722488  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
